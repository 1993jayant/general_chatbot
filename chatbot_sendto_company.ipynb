{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stemmer = LancasterStemmer()\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "# Reading the training data\n",
    "with open('intents.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "try:\n",
    "    with open('ys_dict.pickle', 'rb') as f:\n",
    "        ys_ohe, ys_dict, xs_vec = pickle.load(f)\n",
    "        \n",
    "except:\n",
    "    # Reading each sentence and corresponding class label\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for d in data['intents']:\n",
    "        for dd in d['patterns']:\n",
    "\n",
    "            xs.append(dd) # input data\n",
    "            ys.append(d['tag']) # class labels\n",
    "\n",
    "    # Reading the GLoVe vectors file\n",
    "    with open(r\"D:\\b\\my work\\programming\\appliedaicourse\\applied ai ipython notebooks\\assignments\\glove_vectors\", 'rb') as file:\n",
    "        glove = pickle.load(file)\n",
    "\n",
    "    # Vocabulary of GLoVe words\n",
    "    glove_words = set(glove.keys())\n",
    "\n",
    "    # encoding each sentence in training data using glove vectors with averaging\n",
    "    xs_vec = []\n",
    "    for sent in xs:\n",
    "\n",
    "        vec = np.zeros(300)\n",
    "        cnt = 0\n",
    "\n",
    "        for word in sent.split():\n",
    "            if word.lower() in glove_words:\n",
    "\n",
    "                vec += glove[word.lower()]\n",
    "                cnt += 1\n",
    "\n",
    "        if cnt != 0:\n",
    "            vec /= cnt\n",
    "\n",
    "        xs_vec.append(vec)\n",
    "    xs_vec = np.array(xs_vec)\n",
    "\n",
    "    # converting 'ys' into OHE vector\n",
    "    ys_dict = CountVectorizer()\n",
    "    ys_ohe = ys_dict.fit_transform(ys)\n",
    "    ys_dict = ys_dict.get_feature_names()\n",
    "\n",
    "    with open('ys_dict.pickle', 'wb') as f:\n",
    "        pickle.dump((ys_ohe, ys_dict, xs_vec), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the tensorflow graph to default state\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "39/39 [==============================] - 0s 8ms/step - loss: 2.4241 - accuracy: 0.0513\n",
      "Epoch 2/200\n",
      "39/39 [==============================] - 0s 974us/step - loss: 2.4062 - accuracy: 0.0513\n",
      "Epoch 3/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 2.3947 - accuracy: 0.0513\n",
      "Epoch 4/200\n",
      "39/39 [==============================] - 0s 769us/step - loss: 2.3860 - accuracy: 0.0769\n",
      "Epoch 5/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 2.3781 - accuracy: 0.1026\n",
      "Epoch 6/200\n",
      "39/39 [==============================] - 0s 692us/step - loss: 2.3705 - accuracy: 0.1026\n",
      "Epoch 7/200\n",
      "39/39 [==============================] - 0s 744us/step - loss: 2.3598 - accuracy: 0.1282\n",
      "Epoch 8/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 2.3511 - accuracy: 0.1282\n",
      "Epoch 9/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 2.3393 - accuracy: 0.1282\n",
      "Epoch 10/200\n",
      "39/39 [==============================] - 0s 718us/step - loss: 2.3306 - accuracy: 0.1538\n",
      "Epoch 11/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 2.3160 - accuracy: 0.1282\n",
      "Epoch 12/200\n",
      "39/39 [==============================] - 0s 795us/step - loss: 2.3057 - accuracy: 0.1538\n",
      "Epoch 13/200\n",
      "39/39 [==============================] - 0s 821us/step - loss: 2.2898 - accuracy: 0.1538\n",
      "Epoch 14/200\n",
      "39/39 [==============================] - 0s 692us/step - loss: 2.2756 - accuracy: 0.1538\n",
      "Epoch 15/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 2.2635 - accuracy: 0.1282\n",
      "Epoch 16/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 2.2509 - accuracy: 0.1538\n",
      "Epoch 17/200\n",
      "39/39 [==============================] - 0s 821us/step - loss: 2.2378 - accuracy: 0.1538\n",
      "Epoch 18/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 2.2260 - accuracy: 0.1795\n",
      "Epoch 19/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 2.2116 - accuracy: 0.1795\n",
      "Epoch 20/200\n",
      "39/39 [==============================] - 0s 692us/step - loss: 2.1990 - accuracy: 0.2308\n",
      "Epoch 21/200\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.1871 - accuracy: 0.2308\n",
      "Epoch 22/200\n",
      "39/39 [==============================] - 0s 718us/step - loss: 2.1753 - accuracy: 0.2308\n",
      "Epoch 23/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 2.1621 - accuracy: 0.2308\n",
      "Epoch 24/200\n",
      "39/39 [==============================] - 0s 949us/step - loss: 2.1458 - accuracy: 0.2564\n",
      "Epoch 25/200\n",
      "39/39 [==============================] - 0s 821us/step - loss: 2.1341 - accuracy: 0.3077\n",
      "Epoch 26/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 2.1213 - accuracy: 0.3590\n",
      "Epoch 27/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 2.1083 - accuracy: 0.3590\n",
      "Epoch 28/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 2.0971 - accuracy: 0.3590\n",
      "Epoch 29/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 2.0818 - accuracy: 0.3590\n",
      "Epoch 30/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 2.0698 - accuracy: 0.3590\n",
      "Epoch 31/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 2.0564 - accuracy: 0.3846\n",
      "Epoch 32/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 2.0452 - accuracy: 0.3590\n",
      "Epoch 33/200\n",
      "39/39 [==============================] - 0s 744us/step - loss: 2.0328 - accuracy: 0.3590\n",
      "Epoch 34/200\n",
      "39/39 [==============================] - ETA: 0s - loss: 2.1197 - accuracy: 0.20 - 0s 538us/step - loss: 2.0197 - accuracy: 0.3590\n",
      "Epoch 35/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 2.0081 - accuracy: 0.3333\n",
      "Epoch 36/200\n",
      "39/39 [==============================] - ETA: 0s - loss: 2.0513 - accuracy: 0.50 - 0s 538us/step - loss: 1.9958 - accuracy: 0.3590\n",
      "Epoch 37/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 1.9829 - accuracy: 0.3333\n",
      "Epoch 38/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 1.9703 - accuracy: 0.3333\n",
      "Epoch 39/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.9571 - accuracy: 0.3333\n",
      "Epoch 40/200\n",
      "39/39 [==============================] - 0s 692us/step - loss: 1.9419 - accuracy: 0.3333\n",
      "Epoch 41/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 1.9296 - accuracy: 0.3333\n",
      "Epoch 42/200\n",
      "39/39 [==============================] - 0s 795us/step - loss: 1.9189 - accuracy: 0.3333\n",
      "Epoch 43/200\n",
      "39/39 [==============================] - 0s 974us/step - loss: 1.9046 - accuracy: 0.3333\n",
      "Epoch 44/200\n",
      "39/39 [==============================] - 0s 821us/step - loss: 1.8929 - accuracy: 0.3333\n",
      "Epoch 45/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.8815 - accuracy: 0.3590\n",
      "Epoch 46/200\n",
      "39/39 [==============================] - 0s 744us/step - loss: 1.8713 - accuracy: 0.3590\n",
      "Epoch 47/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.8578 - accuracy: 0.3590\n",
      "Epoch 48/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 1.8484 - accuracy: 0.3590\n",
      "Epoch 49/200\n",
      "39/39 [==============================] - 0s 769us/step - loss: 1.8381 - accuracy: 0.3590\n",
      "Epoch 50/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 1.8273 - accuracy: 0.3590\n",
      "Epoch 51/200\n",
      "39/39 [==============================] - ETA: 0s - loss: 1.7129 - accuracy: 0.40 - 0s 615us/step - loss: 1.8171 - accuracy: 0.3590\n",
      "Epoch 52/200\n",
      "39/39 [==============================] - 0s 385us/step - loss: 1.8046 - accuracy: 0.3590\n",
      "Epoch 53/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 1.7930 - accuracy: 0.3590\n",
      "Epoch 54/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 1.7813 - accuracy: 0.3590\n",
      "Epoch 55/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 1.7667 - accuracy: 0.3846\n",
      "Epoch 56/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 1.7549 - accuracy: 0.4103\n",
      "Epoch 57/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 1.7428 - accuracy: 0.4103\n",
      "Epoch 58/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 1.7256 - accuracy: 0.4103\n",
      "Epoch 59/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 1.7122 - accuracy: 0.4103\n",
      "Epoch 60/200\n",
      "39/39 [==============================] - 0s 744us/step - loss: 1.7007 - accuracy: 0.4103\n",
      "Epoch 61/200\n",
      "39/39 [==============================] - 0s 846us/step - loss: 1.6857 - accuracy: 0.4103\n",
      "Epoch 62/200\n",
      "39/39 [==============================] - 0s 795us/step - loss: 1.6691 - accuracy: 0.4103\n",
      "Epoch 63/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 1.6591 - accuracy: 0.4103\n",
      "Epoch 64/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 1.6423 - accuracy: 0.4103\n",
      "Epoch 65/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.6310 - accuracy: 0.4359\n",
      "Epoch 66/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.6160 - accuracy: 0.4615\n",
      "Epoch 67/200\n",
      "39/39 [==============================] - 0s 385us/step - loss: 1.6014 - accuracy: 0.4615\n",
      "Epoch 68/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.5838 - accuracy: 0.5128\n",
      "Epoch 69/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.5689 - accuracy: 0.5385\n",
      "Epoch 70/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 1.5540 - accuracy: 0.5385\n",
      "Epoch 71/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.5404 - accuracy: 0.5385\n",
      "Epoch 72/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 1.5240 - accuracy: 0.5385\n",
      "Epoch 73/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 1.5071 - accuracy: 0.5385\n",
      "Epoch 74/200\n",
      "39/39 [==============================] - 0s 359us/step - loss: 1.4892 - accuracy: 0.5385\n",
      "Epoch 75/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 1.4748 - accuracy: 0.5385\n",
      "Epoch 76/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 1.4581 - accuracy: 0.5128\n",
      "Epoch 77/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 1.4415 - accuracy: 0.5128\n",
      "Epoch 78/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 1.4251 - accuracy: 0.5128\n",
      "Epoch 79/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.4052 - accuracy: 0.5128\n",
      "Epoch 80/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 1.3848 - accuracy: 0.5641\n",
      "Epoch 81/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.3696 - accuracy: 0.5641\n",
      "Epoch 82/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 1.3440 - accuracy: 0.5897\n",
      "Epoch 83/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 1.3232 - accuracy: 0.6154\n",
      "Epoch 84/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 1.3075 - accuracy: 0.6154\n",
      "Epoch 85/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.2839 - accuracy: 0.6154\n",
      "Epoch 86/200\n",
      "39/39 [==============================] - 0s 872us/step - loss: 1.2647 - accuracy: 0.6410\n",
      "Epoch 87/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.2486 - accuracy: 0.6410\n",
      "Epoch 88/200\n",
      "39/39 [==============================] - 0s 718us/step - loss: 1.2312 - accuracy: 0.6154\n",
      "Epoch 89/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 1.2121 - accuracy: 0.6154\n",
      "Epoch 90/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.1934 - accuracy: 0.6410\n",
      "Epoch 91/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 1.1760 - accuracy: 0.6410\n",
      "Epoch 92/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 1.1576 - accuracy: 0.6667\n",
      "Epoch 93/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 1.1417 - accuracy: 0.6667\n",
      "Epoch 94/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 1.1245 - accuracy: 0.6667\n",
      "Epoch 95/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.1069 - accuracy: 0.6667\n",
      "Epoch 96/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 1.0948 - accuracy: 0.6667\n",
      "Epoch 97/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 1.0772 - accuracy: 0.6667\n",
      "Epoch 98/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 1.0629 - accuracy: 0.6923\n",
      "Epoch 99/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 1.0474 - accuracy: 0.6923\n",
      "Epoch 100/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 1.0316 - accuracy: 0.6923\n",
      "Epoch 101/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 1.0174 - accuracy: 0.7179\n",
      "Epoch 102/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 1.0021 - accuracy: 0.7179\n",
      "Epoch 103/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.9877 - accuracy: 0.7179\n",
      "Epoch 104/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.9734 - accuracy: 0.7436\n",
      "Epoch 105/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 0.9623 - accuracy: 0.7436\n",
      "Epoch 106/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.9472 - accuracy: 0.7436\n",
      "Epoch 107/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.9352 - accuracy: 0.7436\n",
      "Epoch 108/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 0.9218 - accuracy: 0.7436\n",
      "Epoch 109/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 0.9092 - accuracy: 0.7436\n",
      "Epoch 110/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.8956 - accuracy: 0.7436\n",
      "Epoch 111/200\n",
      "39/39 [==============================] - 0s 769us/step - loss: 0.8836 - accuracy: 0.7436\n",
      "Epoch 112/200\n",
      "39/39 [==============================] - 0s 718us/step - loss: 0.8719 - accuracy: 0.7436\n",
      "Epoch 113/200\n",
      "39/39 [==============================] - 0s 821us/step - loss: 0.8600 - accuracy: 0.7436\n",
      "Epoch 114/200\n",
      "39/39 [==============================] - 0s 897us/step - loss: 0.8491 - accuracy: 0.7436\n",
      "Epoch 115/200\n",
      "39/39 [==============================] - 0s 872us/step - loss: 0.8382 - accuracy: 0.7436\n",
      "Epoch 116/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.8269 - accuracy: 0.7436\n",
      "Epoch 117/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.8158 - accuracy: 0.7436\n",
      "Epoch 118/200\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.7657 - accuracy: 0.80 - 0s 564us/step - loss: 0.8037 - accuracy: 0.7436\n",
      "Epoch 119/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.7933 - accuracy: 0.7436\n",
      "Epoch 120/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 0.7836 - accuracy: 0.7436\n",
      "Epoch 121/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 0.7735 - accuracy: 0.7436\n",
      "Epoch 122/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 0.7614 - accuracy: 0.7436\n",
      "Epoch 123/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 0.7483 - accuracy: 0.7436\n",
      "Epoch 124/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.7360 - accuracy: 0.7436\n",
      "Epoch 125/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.7261 - accuracy: 0.7436\n",
      "Epoch 126/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.7132 - accuracy: 0.7436\n",
      "Epoch 127/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.7040 - accuracy: 0.7436\n",
      "Epoch 128/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.6927 - accuracy: 0.7436\n",
      "Epoch 129/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.6833 - accuracy: 0.7436\n",
      "Epoch 130/200\n",
      "39/39 [==============================] - 0s 718us/step - loss: 0.6734 - accuracy: 0.7692\n",
      "Epoch 131/200\n",
      "39/39 [==============================] - 0s 769us/step - loss: 0.6642 - accuracy: 0.7949\n",
      "Epoch 132/200\n",
      "39/39 [==============================] - 0s 692us/step - loss: 0.6560 - accuracy: 0.7949\n",
      "Epoch 133/200\n",
      "39/39 [==============================] - 0s 718us/step - loss: 0.6466 - accuracy: 0.7949\n",
      "Epoch 134/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.6380 - accuracy: 0.7949\n",
      "Epoch 135/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 0.6303 - accuracy: 0.7949\n",
      "Epoch 136/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.6233 - accuracy: 0.7949\n",
      "Epoch 137/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 0.6140 - accuracy: 0.7949\n",
      "Epoch 138/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 0.6060 - accuracy: 0.8205\n",
      "Epoch 139/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 0.5997 - accuracy: 0.7949\n",
      "Epoch 140/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.5915 - accuracy: 0.8205\n",
      "Epoch 141/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 0.5850 - accuracy: 0.8205\n",
      "Epoch 142/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.5780 - accuracy: 0.8205\n",
      "Epoch 143/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.5715 - accuracy: 0.8205\n",
      "Epoch 144/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 0.5640 - accuracy: 0.8462\n",
      "Epoch 145/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 0.5579 - accuracy: 0.8462\n",
      "Epoch 146/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.5538 - accuracy: 0.8462\n",
      "Epoch 147/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.5473 - accuracy: 0.8462\n",
      "Epoch 148/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 0.5403 - accuracy: 0.8462\n",
      "Epoch 149/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.5345 - accuracy: 0.8462\n",
      "Epoch 150/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.5283 - accuracy: 0.8462\n",
      "Epoch 151/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.5210 - accuracy: 0.8718\n",
      "Epoch 152/200\n",
      "39/39 [==============================] - 0s 385us/step - loss: 0.5145 - accuracy: 0.8718\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 436us/step - loss: 0.5070 - accuracy: 0.8718\n",
      "Epoch 154/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 0.4967 - accuracy: 0.8718\n",
      "Epoch 155/200\n",
      "39/39 [==============================] - 0s 385us/step - loss: 0.4860 - accuracy: 0.9231\n",
      "Epoch 156/200\n",
      "39/39 [==============================] - 0s 539us/step - loss: 0.4760 - accuracy: 0.9231\n",
      "Epoch 157/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.4678 - accuracy: 0.9231\n",
      "Epoch 158/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 0.4589 - accuracy: 0.9231\n",
      "Epoch 159/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 0.4495 - accuracy: 0.9231\n",
      "Epoch 160/200\n",
      "39/39 [==============================] - 0s 436us/step - loss: 0.4414 - accuracy: 0.9231\n",
      "Epoch 161/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.4354 - accuracy: 0.9231\n",
      "Epoch 162/200\n",
      "39/39 [==============================] - 0s 590us/step - loss: 0.4278 - accuracy: 0.9231\n",
      "Epoch 163/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.4214 - accuracy: 0.9231\n",
      "Epoch 164/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.4136 - accuracy: 0.9231\n",
      "Epoch 165/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.4094 - accuracy: 0.9231\n",
      "Epoch 166/200\n",
      "39/39 [==============================] - 0s 385us/step - loss: 0.4016 - accuracy: 0.9231\n",
      "Epoch 167/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.3965 - accuracy: 0.9231\n",
      "Epoch 168/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.3903 - accuracy: 0.9231\n",
      "Epoch 169/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.3843 - accuracy: 0.9231\n",
      "Epoch 170/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.3805 - accuracy: 0.9231\n",
      "Epoch 171/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.3748 - accuracy: 0.9231\n",
      "Epoch 172/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.3700 - accuracy: 0.9231\n",
      "Epoch 173/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.3660 - accuracy: 0.9231\n",
      "Epoch 174/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.3617 - accuracy: 0.9231\n",
      "Epoch 175/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.3561 - accuracy: 0.9231\n",
      "Epoch 176/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.3522 - accuracy: 0.9231\n",
      "Epoch 177/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.3482 - accuracy: 0.9231\n",
      "Epoch 178/200\n",
      "39/39 [==============================] - 0s 462us/step - loss: 0.3438 - accuracy: 0.9231\n",
      "Epoch 179/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.3392 - accuracy: 0.9231\n",
      "Epoch 180/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.3370 - accuracy: 0.9231\n",
      "Epoch 181/200\n",
      "39/39 [==============================] - 0s 487us/step - loss: 0.3316 - accuracy: 0.9231\n",
      "Epoch 182/200\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.4558 - accuracy: 0.90 - 0s 513us/step - loss: 0.3287 - accuracy: 0.9231\n",
      "Epoch 183/200\n",
      "39/39 [==============================] - 0s 410us/step - loss: 0.3264 - accuracy: 0.9231\n",
      "Epoch 184/200\n",
      "39/39 [==============================] - 0s 538us/step - loss: 0.3214 - accuracy: 0.9231\n",
      "Epoch 185/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.3168 - accuracy: 0.9231\n",
      "Epoch 186/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.3138 - accuracy: 0.9231\n",
      "Epoch 187/200\n",
      "39/39 [==============================] - 0s 692us/step - loss: 0.3098 - accuracy: 0.9231\n",
      "Epoch 188/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 0.3071 - accuracy: 0.9231\n",
      "Epoch 189/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.3020 - accuracy: 0.9231\n",
      "Epoch 190/200\n",
      "39/39 [==============================] - 0s 641us/step - loss: 0.2997 - accuracy: 0.9231\n",
      "Epoch 191/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 0.2960 - accuracy: 0.9231\n",
      "Epoch 192/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 0.2928 - accuracy: 0.9231\n",
      "Epoch 193/200\n",
      "39/39 [==============================] - 0s 615us/step - loss: 0.2893 - accuracy: 0.9231\n",
      "Epoch 194/200\n",
      "39/39 [==============================] - 0s 667us/step - loss: 0.2874 - accuracy: 0.9231\n",
      "Epoch 195/200\n",
      "39/39 [==============================] - 0s 513us/step - loss: 0.2844 - accuracy: 0.9231\n",
      "Epoch 196/200\n",
      "39/39 [==============================] - 0s 872us/step - loss: 0.2813 - accuracy: 0.9231\n",
      "Epoch 197/200\n",
      "39/39 [==============================] - 0s 769us/step - loss: 0.2777 - accuracy: 0.9231\n",
      "Epoch 198/200\n",
      "39/39 [==============================] - 0s 821us/step - loss: 0.2736 - accuracy: 0.9231\n",
      "Epoch 199/200\n",
      "39/39 [==============================] - 0s 744us/step - loss: 0.2690 - accuracy: 0.9231\n",
      "Epoch 200/200\n",
      "39/39 [==============================] - 0s 564us/step - loss: 0.2648 - accuracy: 0.9231\n"
     ]
    }
   ],
   "source": [
    "# initializing the model architecture using keras sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = xs_vec.shape[1], activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "model.add(Dense(8, activation = 'relu', kernel_initializer = 'he_normal'))\n",
    "model.add(Dense(ys_ohe.shape[1], activation = 'softmax'))\n",
    "\n",
    "try:\n",
    "    with open('model.json', 'r') as m:\n",
    "        model = model_from_json(m.read()) # else we can use model = load_model('abc.h5') if architecture and weights are in a single file\n",
    "        model.load_weights('model_weights.h5')\n",
    "\n",
    "except:\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    history = model.fit(xs_vec, ys_ohe, batch_size = 10, epochs = 200)\n",
    "\n",
    "    with open('model.json', 'w') as m:\n",
    "        m.write(model.to_json()) # else we can simply use model.save('abc.h5') to save both architecture and weights in a single file\n",
    "        model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the accuracy plot\n",
    "plt.plot(history.history['accuracy'], label = 'Train accuracy')\n",
    "plt.title('Accuracy plot')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function embedding input sentence into glove embeddings\n",
    "def sent_embeddings(ip_sent, glove, glove_words):\n",
    "    \n",
    "    sent_emb = np.zeros(300)\n",
    "    cnt = 0\n",
    "    \n",
    "    for word in ip_sent.split():\n",
    "        if word.lower() in glove_words:\n",
    "            sent_emb += glove[word.lower()]\n",
    "            cnt += 1\n",
    "        \n",
    "    if cnt != 0:\n",
    "        sent_emb /= cnt\n",
    "        \n",
    "    return sent_emb.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with the BOT (Type \"quit\" or \"exit\" to stop)!\n",
      "You: hello\n",
      "Hello!\n",
      "You: what is your name\n",
      "You can call me Jayant\n",
      "You: you are amazing\n",
      "I request you to please ask me something else.\n",
      "You: exit\n"
     ]
    }
   ],
   "source": [
    "# function to start the chat\n",
    "def chat():\n",
    "    \n",
    "#     loading glove model for word embeddings of input sentence\n",
    "    with open(r'D:\\b\\my work\\programming\\appliedaicourse\\applied ai ipython notebooks\\assignments\\glove_vectors', 'rb') as f:\n",
    "        \n",
    "        glove = pickle.load(f)\n",
    "        glove_words = glove.keys()\n",
    "        \n",
    "    print('Start talking with the BOT (Type \"quit\" or \"exit\" to stop)!')\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        inp = input('You: ')\n",
    "        \n",
    "        if inp.lower() == 'quit' or inp.lower() == 'exit':\n",
    "            break\n",
    "        \n",
    "        results = model.predict(sent_embeddings(inp, glove, glove_words)) # function to embed sentence using glove model.\n",
    "\n",
    "        results_index = np.argmax(results)\n",
    "\n",
    "        tag = ys_dict[results_index]\n",
    "        \n",
    "        if results[0, results_index] > 0.7: # threshold to give the exact output\n",
    "            for tg in data['intents']:\n",
    "                if tg['tag'] == tag:\n",
    "                    responses = tg['responses']\n",
    "\n",
    "            print(random.choice(responses))\n",
    "            \n",
    "        else: # if model is not confident even 70 percent\n",
    "            neg_responses = ['I didn\\'t get that, try again.', 'I request you to please ask me something else.', \\\n",
    "                             'Ask me something else.', 'I have not yet learned about that.', \\\n",
    "                             'I wish I could have helped, please ask something else.', 'really sorry, I don\\'t have an answer to that yet']\n",
    "            print(random.choice(neg_responses))\n",
    "            \n",
    "# calling the chat function\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
